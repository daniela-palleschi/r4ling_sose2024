---
title: "Deskriptive Statistik"
subtitle: "Maße der zentralen Tendenz und Streuung"
author: "Daniela Palleschi"
institute: Humboldt-Universität zu Berlin
footer: "Woche 8 - Deskriptive Statistik" 
lang: de
date: "12/06/2023"
date-format: "ddd [den] DD.MM.YYYY"
date-modified: last-modified
format: 
  html:
    output-file: descr_stats_blatt_DE.html
    include-after-body: ../../custom.html
    number-sections: true
    number-depth: 3
    toc: true
    toc-title: "heutige Themen"
    code-overflow: wrap
    code-tools: true
    self-contained: true
    include-in-header: ../../mathjax.html
  revealjs: 
    output-file: descr_stats_folien_DE.html
    include-in-header: ../../mathjax.html
    include-after-body: ../../custom.html
    theme: [dark]
    width: 1600
    height: 900
    progress: true
    # smaller: true
    scrollable: true
    slide-number: c/t
    code-link: true
    code-overflow: wrap
    code-tools: true
    # logo: logos/hu_logo.png
    # css: logo.css
    incremental: true
    number-depth: 1
    toc: false
    toc-depth: 1
    toc-title: 'Überblick'
    navigation-mode: linear
    controls-layout: bottom-right
    fig-cap-location: top
    font-size: 0.6em
    slide-level: 4
    self-contained: true
    # chalkboard: true
    title-slide-attributes: 
      data-background-image: logos/logos.tif
      data-background-size: 15%
      data-background-position: 50% 92%
    execute:
      fig-out: 6
      fig-asp: .618
  pdf:
    output-file: descr_stats_DE.pdf
    toc: true
    number-sections: true
    colorlinks: true
    code-overflow: wrap
bibliography: ../../references.bib
csl: ../../apa.csl
editor_options: 
  chunk_output_type: console
---

```{r}
#| echo: false
knitr::opts_chunk$set(eval = T, # evaluate chunks
                      echo = T, # 'print code chunk?'
                      message = F, # 'print messages (e.g., warnings)?'
                      error = F, # stop when error encountered
                      warning = F) # don't print warnings
```

```{r, eval = T, cache = F}
#| echo: false
# Create references.json file based on the citations in this script
# make sure you have 'bibliography: references.json' in the YAML
# rbbt::bbt_update_bib("_descr_stats_DE.qmd")
```

# Lernziele {.unnumbered}

Heute werden wir lernen...

- über Maße der zentralen Tendenz (Mittelwert, Median, Modus)
- über Streuungsmaße (Bereich, Standardabweichung)
- wie man die Funktion `summarise()` von `dplyr` benutzt
- wie man Zusammenfassungen `.by` Gruppe erstellt

# Lektüre {.unnummeriert}

Die erforderliche Lektüre für dieses Thema sind:

1.  Kap. 3, Abschnitte 3.4-3.9 (*Descriptive statistics, models, and distributions*) in @winter_statistics_2019 (online verfügbar für Studierende/Beschäftigte der HU Berlin über das [HU Grimm Zentrum](https://hu-berlin.hosted.exlibrisgroup.com/permalink/f/uig076/TN_cdi_askewsholts_vlebooks_9781351677431).

2.  [Abschnitt 4.5 (Groups)](https://r4ds.hadley.nz/data-transform#groups) in Kap. 4 (*Data Transformation*) in @wickham_r_2023.

# Einrichten

# Umgebung löschen

- Starten Sie ein neues Skript *immer* mit einer leeren R-Umgebung
    - keine Objekte in der Umgebung gespeichert
    - keine Pakete geladen
- Klicken Sie auf `Session > Restart R`, um mit einer neuen Umgebung zu beginnen
    - oder das Tastaturkürzel `Cmd/Ctrl+Strg+0`

## Pakete

```{r}
pacman::p_load(tidyverse,
               here,
               janitor)
```

```{r}
#| echo: false
pacman::p_load(patchwork)
```

## Daten laden

- zwei Datensätze heute:
    - `groesse_geburtstag_ws2324.csv`: ein leicht veränderter `groesse_geburtstag`-Datensatz von letzter Woche
    - `languageR_english.csv`: komprimierte Version des `english`-Datensatzes aus dem `languageR`-Paket
- wenn Sie diese Daten noch nicht haben, laden Sie sie von Moodle herunter

```{r}
#| eval: false
#| echo: false
library(languageR)

df_eng <- english |> 
  select(AgeSubject, Word, LengthInLetters, WrittenFrequency, WordCategory, RTlexdec, RTnaming) |>   mutate(RTlexdec = exp(RTlexdec),
         RTnaming = exp(RTnaming),
         RTnaming = ifelse(Word == "age" & AgeSubject == "young", NA, RTnaming)) 

write_csv(df_eng, here("daten", "languageR_english.csv"))

df_groesse <- read_csv(here("daten", "groesse_geburtstag_ws2324.csv"),
                       # fix N/A values
                       na = c("", "N/A")) |> 
  mutate(Größe = ifelse(Größe == 168, 167, Größe)) |> 
  clean_names() |> 
  rename(groesse = groesse,
         muttersprache = l1,
         geburtsmonat = monat_der_geburt,
         geburtstag = tag)

write_csv(df_groesse, here("daten", "groesse_geburtstag_ws2324.csv"))
```

```{r}
df_groesse <- read_csv(here("daten", "groesse_geburtstag_ws2324.csv"))
```

```{r}
df_eng <- read_csv(here("daten", "languageR_english.csv")) |> 
  clean_names() |> 
  # fix some wonky variable names:
  rename(rt_lexdec = r_tlexdec,
         rt_naming = r_tnaming)
```

# Deskriptive Statistik

- beschreibt quantitativ die zentrale Tendenz, Variabilität und Verteilung von Daten
    - auch zusammenfassende Statistik genannt
- z.B. Wertebereich (Minimum, Maximum), der Mittelwert und die Standardabweichung

## Anzahl der Beobachtungen ($n$)

- ist keine Statistik, aber eine wichtige Information
    - mehr Daten (höher $n$) = mehr Beweise
    - weniger Daten (niedriger $n$) = möglicherweise nicht verallgemeinerbar auf die breitere Population
- `nrow()`: liefert die Anzahl der Beobachtungen in einem Datensatz

```{r}
#| output-location: fragment
nrow(df_groesse)
```

- `length()`: die Anzahl der Beobachtungen in einem Vektor oder einer Variablen

```{r}
#| output-location: fragment
length(df_groesse$groesse)
```

## Maße der zentralen Tendenz (Lagemaße)

- beschreiben quantitativ die Mitte unserer Daten
    - der Mittelwert, der Median und der Modus

### Mittelwert ($\mu$)

- der Mittelwert oder Durchschnitt: die Summe aller Werte geteilt durch die Anzahl der Werte (wie in Gleichung \ref{eq-mean})

\begin{align}
\mu &= \frac{Summe\;der\;Werte} 
           {n} \label{eq-mean} 
\end{align}

---

- können wir die Ergebnisse einer Gleichung als Objekt speichern
    - oder mehrere Werte als Vektor (eine Liste von Werten der gleichen Klasse)

```{r}
#| output-location: fragment
# save heights as a vector
heights <- c(171, 168, 182, 190, 170, 163, 164, 167, 189)
```

- könnten wir dann die Funktionen `sum()` und `length()` verwenden, um den Mittelwert zu berechnen

```{r}
#| output-location: fragment
# divide the sum of heights by the n of heights
sum(heights)/length(heights)
```

-   or simply use the `mean()` function.

```{r}
#| output-location: fragment
# or use the mean() function
mean(heights)
```

---

- Wir können die Funktion `mean()` auch auf eine Variable in einem Datenrahmen anwenden, indem wir den Operator `$` verwenden (`datenrahmen$variable`).

```{r}
#| output-location: fragment
mean(df_groesse$groesse)
```

### Median

- der Wert in der Mitte des Datensatzes
- Wenn Sie Ihre Daten in der Reihenfolge ihrer Werte anordnen, liegt die Hälfte der Daten unter dem Median, die andere Hälfte darüber.

#### Median in R

- können wir die Funktion `sort()` verwenden und zählen, welches der mittlere Wert ist:

```{r}
#| output-location: fragment
sort(df_groesse$groesse)
```

- alternativ könnte man auch einfach die Funktion `median()` verwenden

```{r}
#| output-location: fragment
median(df_groesse$groesse)
```

### Modus

- der Wert, der am häufigsten in einem Datensatz vorkommt
- keine R-Funktion zur Bestimmung des Modus
    - aber wir können ihn visualisieren, z.B. mit einem Histogramm oder einem Dichteplot

```{r}
#| output-location: column-fragment
df_groesse |>
  ggplot(aes(x = groesse)) +
  geom_histogram(binwidth = .5) +
  scale_y_continuous(breaks = c(1,2)) +
  theme_bw() +
  theme(axis.text = element_text(size = 15),
        axis.title = element_text(size = 20, face = "bold"))
```

## Streuungsmaße

- beschreiben die Streuung von Datenpunkten
    - sagen uns etwas darüber, wie die Daten insgesamt verteilt sind

### Bereich

- kann sich auf den höchsten (Maximum) und den niedrigsten (Minimum) Wert beziehen
    - oder die Differenz zwischen höchstem und niedrigstem Wert

---

- `max()` und `min()`: gibt den höchsten und den niedrigsten Wert aus

```{r}
#| output-location: fragment
max(heights)
```

```{r}
#| output-location: fragment
min(heights)
```

- oder die Funktion `range()` verwenden

```{r}
#| output-location: fragment
range(heights)
```

---

- Die Differenz zwischen diesen Werten erhält man, indem man den Minimalwert vom Maximalwert subtrahiert

```{r}
#| output-location: fragment
max(heights) - min(heights)
```

---

- In einem Histogramm oder Dichteplot: die niedrigsten und höchsten Werte auf der x-Achse

```{r}
#| echo: false
fig_hist <-
  df_groesse |> 
  ggplot() + 
  aes(x = groesse) + 
  labs(title = "Histogram of heights") +
  scale_y_continuous(breaks = c(1,2)) +
  geom_histogram(binwidth = .5)

fig_dens <-
  df_groesse |> 
  ggplot() + 
  aes(x = groesse) + 
  labs(title = "Density plot of heights") +
  geom_density()

fig_hist + fig_dens
```

### Standardabweichung (`sd` oder $\sigma$)

- ein Maß für die Streuung der Daten *im Verhältnis zum Mittelwert*
    - eine niedrige Standardabweichung bedeutet, dass die Daten um den Mittelwert herum gruppiert sind (d.h. es gibt eine geringere Streuung)
    - eine hohe Standardabweichung bedeutet, dass die Daten stärker gestreut sind
- Die Standardabweichung wird sehr oft angegeben, wenn der Mittelwert angegeben wird.

---

- Standardabweichung (`sd`) = die Quadratwurzel ($\sqrt{}$ oder `sqrt()` in R) der Summe der quadrierten Wertabweichungen vom Mittelwert ($(x - \mu)^2$) geteilt durch die Anzahl der Beobachtungen minus 1 ($n-1$)
    - gegeben in Gleichung \ref{eq-sd}

\begin{align}
\sigma & = \sqrt{\frac{(x_1-\mu)^2 + (x_2-\mu)^2 + ... + (x_N-\mu)^2}{N-1}} \label{eq-sd}
\end{align}

- das sieht einschüchternd aus, aber wir können die Standardabweichung in R mit der Funktion `sd()` berechnen

```{r}
#| output-location: fragment
sd(heights)
```

---

- wir können die Standardabweichung von Hand berechnen, wenn wir wissen:
    - den Wert der einzelnen Beobachtungen
    - den Mittelwert dieser Werte
    - die Anzahl der Beobachtungen

\begin{align}
\sigma_{heights} & = \sqrt{\frac{(height_1-\mu)^2 + (height_2-\mu)^2 + ... (heights_N-\mu)^2}{N-1}} 
\end{align}

---

- In einem Vektor mit 3 Beobachtungen (3, 5, 9) sind unsere Werte ($x$) zum Beispiel folgende:

```{r}
#| output-location: column-fragment
values <- c(3,5,16)
values
```

- Wenn wir diese zu Gleichung \ref{eq-sd} hinzufügen, erhalten wir Gleichung \ref{eq-sd1}

```{=tex}
\begin{align}
\sigma_{values} & = \sqrt{\frac{(3-\mu)^2 + (5-\mu)^2 + (16-\mu)^2}{N-1}} \label{eq-sd1}
\end{align}
```

---

- unser Mittelwert ($\mu$) ist:

```{r}
#| output-location: column-fragment
mean(values)
```

- Wenn wir diese zu Gleichung \ref{eq-sd1} hinzufügen, erhalten wir Gleichung \ref{eq-sd2}.

```{=tex}
\begin{align}
\sigma_{values} & = \sqrt{\frac{(3-8)^2 + (5-8)^2 + (16-8)^2}{N-1}} \label{eq-sd2}
\end{align}
```

---

- die Anzahl der Beobachtungen ($n$) ist:

```{r}
#| output-location: column-fragment
length(values)
```

- Wenn wir diese zu Gleichung \ref{eq-sd2} hinzufügen, erhalten wir Gleichung \ref{eq-sd3}

```{=tex}
\begin{align}
\sigma_{values} & = \sqrt{\frac{(3-8)^2 + (5-8)^2 + (16-8)^2}{3-1}} \label{eq-sd3}
\end{align}
```

---

- Wenn wir die restlichen Operationen durchführen, erhalten wir die Gleichungen \ref{eq-sd4} bis \ref{eq-sd}:

```{=tex}
\begin{align}
\sigma_{values} & = \sqrt{\frac{(-5)^2 + (-3)^2 + (8)^2}{3-1}} \\ \label{eq-sd4}
\\
& = \sqrt{\frac{25 + 9 + 64}{3-1}}
\\
& = \sqrt{\frac{98}{2}} \\
& = \sqrt{49} \\
& = 7
\end{align}
```

- unsere Arbeit überprüfen:

```{r}
#| output-location: column-fragment
sd(values)
```

# Zusammenfassende Statistiken mit R

- das Paket `dplyr` aus dem `tidyverse` hat einige hilfreiche Funktionen, um zusammenfassende Statistiken zu erstellen
- Lassen Sie uns nun den `df_eng`-Datensatz verwenden, um diese `dplyr`-Verben kennenzulernen

## `dplyr::summarise`

- Die Funktion `summarise()` (`dplyr`) berechnet Zusammenfassungen von Daten
    - aber wir müssen ihr sagen, *was* sie berechnen soll, und für welche Variable(n)
- die Funktion `n()` zum Beispiel liefert die Anzahl der Beobachtungen (nur wenn sie innerhalb von `summarise()` oder `mutate()` verwendet wird)

```{r}
#| output-location: fragment
df_eng |>
  summarise(N = n())
```

---

- wir können auch mehrere Berechnungen auf einmal durchführen
    - Ermitteln wir auch den Mittelwert und die Standardabweichung der lexikalischen Entscheidungsaufgabe (`rt_lexdec`, in Millisekunden)

```{r}
#| output-location: fragment
df_eng |>
  summarise(mean_lexdec = mean(rt_lexdec, na.rm=T),
            sd_lexdec = sd(rt_lexdec, na.rm = T),
            N = n()) 
```

---

::: callout-tip
## Fehlende Werte

- Berechnungen sind bei fehlenden Werten nicht möglich
  + die Variable `rt_naming` hat einen fehlenden Wert
  + die Funktion `mean()` funktioniert nicht mit fehlenden Werten

```{r}
#| output-location: column-fragment
df_eng |>
  summarise(mean_naming = mean(rt_naming))
```

- können wir sie mit dem Verb `drop_na()` entfernen

```{r}
#| output-location: column-fragment
df_eng |>
  drop_na() |>
  summarise(mean_naming = mean(rt_naming))
```
:::

# Variablen gruppieren

- Wir wollen normalerweise bestimmte Gruppen *vergleichen*.
    - z. B. den Vergleich von "Groesse" zwischen L1-Sprechergruppen

## `.by =`

- das Argument `.by =` in `summarise()` berechnet unsere Berechnungen für Gruppen innerhalb einer kategorialen Variable

```{r}
#| output-location: fragment
#| code-line-numbers: "6"
df_eng |>
  drop_na() |>
  summarise(mean_lexdec = mean(rt_lexdec),
            sd_lexdec = sd(rt_lexdec),
            N = n(),
            .by = age_subject) |>
  arrange(mean_lexdec)
```

## Group by multiple variables

- wir können auch nach mehreren Variablen gruppieren
    - dafür brauchen wir `Verkettung` (`c()`)

---

```{r}
#| output-location: column-fragment
#| code-line-numbers: "6"
df_eng |>
  drop_na() |>
  summarise(mean_lexdec = mean(rt_lexdec),
            sd_lexdec = sd(rt_lexdec),
            N = n(),
            .by = c(age_subject, word_category)) |>
  arrange(age_subject)
```

# Das Quartett von Anscombe

- Francis Anscombe konstruierte 1973 4 Datensätze, um zu veranschaulichen, wie wichtig es ist, Daten zu visualisieren, bevor man sie analysiert und ein Modell erstellt
- Diese vier Diagramme stellen 4 Datensätze dar, die alle einen nahezu identischen Mittelwert und eine Standardabweichung, aber sehr unterschiedliche Verteilungen aufweisen

---


```{r}
#| echo: false
# https://michael-franke.github.io/intro-data-analysis/Chap-02-04-Anscombe-example.html
data("anscombe")
tidy_anscombe <- anscombe |>
  pivot_longer(
    everything(),
    names_pattern = "(.)(.)",      
    names_to = c(".value", "grp")  
  ) |>
  mutate(grp = paste0("Dataset ", grp)
         ) 
```

:::: columns
::: {.column width="50%"}
```{r}
#| label: tbl-anscombe
#| tbl-cap: Summary stats of Anscombe's quratet datasets
#| echo: false
tidy_anscombe |>
  group_by(grp) |>
  summarise(
    mean_x    = mean(x),
    mean_y    = mean(y),
    min_x     = min(x),
    min_y     = min(y),
    max_x     = max(x),
    max_y     = max(y),
    crrltn    = cor(x, y)
  ) |> 
  rename(dataset = grp) |> 
  mutate(mean_y = round(mean_y,1)) |>
  select(dataset, mean_x, mean_y) |> 
  knitr::kable() |>
  kableExtra::kable_styling(font_size=20)
```
:::
::: {.column width="50%"}

```{r}
#| label: fig-anscombe
#| fig-cap: Plots of Anscombe's quratet distributions
#| echo: false
#| fig-asp: 1
#| out-width: "100%"
tidy_anscombe |>
  ggplot(aes(x, y)) +
    geom_smooth(method = lm, se = F, color = "darkorange") +
    geom_point(size = 2) +
    scale_y_continuous(breaks = scales::pretty_breaks()) +
    scale_x_continuous(breaks = scales::pretty_breaks()) +
    labs(
      title = "Anscombe's Quartet", x = NULL, y = NULL,
      subtitle = bquote(y == 0.5 * x + 3 ~ (r %~~% .82) ~ "for all groups")
    ) +
    facet_wrap(~grp, ncol = 2, scales = "free_x") +
    theme(strip.background = element_rect(fill = "#f2f2f2", colour = "white")) +
  theme(axis.text = element_text(size = 30)) +
  theme_minimal()
```
:::
::::

## DatasaurRus

- datasauRus-Paket [@datasauRus-package] enthält einige weitere Datensätze, die ähnliche Mittelwerte und Standardabweichung, aber unterschiedliche Verteilungen haben
  + angegeben in @tbl-datasauRus

```{r}
pacman::p_load("datasauRus")
```

```{r}
#| label: tbl-datasauRus
#| tbl-cap: Summary stats of datasauRus datasets
#| output-location: column-fragment
#| echo: false
datasaurus_dozen |>
    group_by(dataset) |>
    summarize(
      mean_x    = mean(x),
      mean_y    = mean(y),
      std_dev_x = sd(x),
      std_dev_y = sd(y),
      corr_x_y  = cor(x, y)
    ) |>
  mutate_if(is.numeric, round, 2) |> 
  knitr::kable() |>
  kableExtra::kable_styling(font_size = 20)
```

---

- aber wenn wir sie aufzeichnen, sehen sie alle sehr unterschiedlich aus (@fig-datasauRus)!

```{r}
#| label: fig-datasauRus
#| fig-cap: Plots of datasauRus dataset distributions
#| out-width: "100%"
#| fig-asp: .35
#| echo: false
ggplot(datasaurus_dozen, aes(x = x, y = y, colour = dataset))+
  geom_point(size = .8) +
  labs(title = "DatasauRus dataset distributions") +
  theme_minimal() +
  theme(legend.position = "none")+
  facet_wrap(~dataset, ncol = 7)
```

---

- Also, ***immer die Daten aufzeichnen***
  + Schauen Sie sich nicht nur die deskriptiven Statistiken an!
- Beides ist sehr wichtig für das Verständnis Ihrer Daten.
- Nächste Woche sehen wir uns an, wie wir unsere zusammenfassenden Statistiken darstellen

# Learning objectives 🏁 {.unnumbered .unlisted}

Heute haben wir gelernt...

- über Maße der zentralen Tendenz ✅
- über Streuungsmaße ✅
- wie man die Funktion `summarise()` von `dplyr` benutzt ✅
- wie man Zusammenfassungen `.by` Gruppe erstellt ✅

# Aufgaben

::: nonincremental
1.  Berechnen Sie die Standardabweichung der Werte `152, 19, 1398, 67, 2111`, ohne die Funktion `sd()` zu benutzen.
    - zeige deine Arbeit. Die folgende R-Syntax könnte nützlich sein (je nachdem, wie Sie es machen wollen):
        - `c()`
        - `mean()`
        - `x^2` berechnet das Quadrat eines Wertes (hier, `x`)
        - `sqrt()` errechnet die Quadratwurzel
        - `length()` liefert die Anzahl der Beobachtungen in einem Vektor

```{r}
#| echo: false
#| eval: false
x <- c(152, 19, 1398, 67, 2111)
sqrt((sum((x-mean(x))^2))/(length(x)-1))
```
:::

---

::: nonincremental
2.  Benutze die Funktion `sd()`, um die Standardabweichung der obigen Werte zu drucken. Haben Sie es richtig gemacht?
3.  Benutze `summarise`, um den Mittelwert, die Standardabweichung und die Anzahl der Beobachtungen für `rt_naming` im `df_lexdec` Datenrahmen zu drucken.
    - Hinweis: Müssen Sie fehlende Werte (`NA`) entfernen?
4.  Machen Sie dasselbe, aber fügen Sie das Argument `.by()` hinzu, um die mittlere Reaktionszeit der Benennungsaufgabe (`rt_naming`) pro Altersgruppe zu ermitteln
    - Ordnen Sie die Ausgabe nach der mittleren Antwortzeit für die Namensgebung an.
:::

# Session Info {.unnumbered}

```{r}
#| eval: false
#| echo: false
RStudio.Version()$version
RStudio.Version()$release_name
```

Erstellt mit `r R.version.string` (`r R.version$nickname`) und RStudioversion 2023.9.0.463 (Desert Sunflower).

```{r}
sessionInfo()
```

# Literaturverzeichnis {.unlisted .unnumbered visibility="uncounted"}

::: {#refs custom-style="Bibliography"}
:::
