---
title: "Deskriptive Statistik"
subtitle: "Ma√üe der zentralen Tendenz und Streuung"
author: "Daniela Palleschi"
institute: Humboldt-Universit√§t zu Berlin
footer: "Woche 9 - Deskriptive Statistik" 
lang: de
date: "`r Sys.Date()`"
format: 
  html:
    output-file: descr_stats_blatt_EN.html
    include-after-body: custom.html
    number-sections: true
    number-depth: 3
    toc: true
    toc-title: "heutige Themen"
    code-overflow: wrap
    code-tools: true
    self-contained: true
    include-in-header: ../../mathjax.html
  revealjs: 
    output-file: descr_stats_folien_EN.html
    include-after-body: custom.html
    theme: [dark]
    width: 1600
    height: 900
    progress: true
    # smaller: true
    scrollable: true
    slide-number: c/t
    code-link: true
    code-overflow: wrap
    code-tools: true
    # logo: logos/hu_logo.png
    # css: logo.css
    incremental: true
    number-depth: 1
    toc: true
    toc-depth: 1
    toc-title: '√úberblick'
    navigation-mode: linear
    controls-layout: bottom-right
    fig-cap-location: top
    font-size: 0.6em
    slide-level: 4
    self-contained: true
    # chalkboard: true
    title-slide-attributes: 
      data-background-image: logos/logos.tif
      data-background-size: 15%
      data-background-position: 50% 92%
    include-in-header: ../../mathjax.html
    execute:
      fig-out: 6
      fig-asp: .618
  pdf:
    output-file: descr_stats_EN.pdf
    toc: true
    number-sections: true
    colorlinks: true
    code-overflow: wrap
bibliography: ../../references.bib
csl: ../../apa.csl
editor_options: 
  chunk_output_type: console
---

```{r}
#| echo: false
knitr::opts_chunk$set(eval = T, # evaluate chunks
                      echo = T, # 'print code chunk?'
                      message = F, # 'print messages (e.g., warnings)?'
                      error = F, # stop when error encountered
                      warning = F) # don't print warnings
```

```{r, eval = T, cache = F}
#| echo: false
# Create references.json file based on the citations in this script
# make sure you have 'bibliography: references.json' in the YAML
# rbbt::bbt_update_bib("_descr_stats_EN.qmd")
```

# Learning objects {.unnumbered}

Today we will learn...

-   about measures of central tendency (mean, median, mode)
-   about measures of dispersion (range, standard deviation)
-   how to use the `summarise()` function from `dplyr`
-   how to produce summaries `.by` group

# Readings {.unnumbered}

The required readings for this topic are:

1.  Ch. 3, Sections 3.4-3.9 (*Descriptive statistics, models, and distributions*) in @winter_statistics_2019 (available online for students/employees of the HU Berlin via the [HU Grimm Zentrum](https://hu-berlin.hosted.exlibrisgroup.com/permalink/f/uig076/TN_cdi_askewsholts_vlebooks_9781351677431).

2.  [Section 4.5 (Groups)](https://r4ds.hadley.nz/data-transform#groups) in Ch. 4 (*Data Transformation*) in @wickham_r_2023.

# Set-up

## Clear Environment

-   *always* start a new script with a clear R environment
    -   no objects stored in the Environment
    -   no packages loaded
-   click `Session > Restart R` to start with a fresh environment
    -   or the keyboard shortcut `Cmd/Ctrl+Strg+0`

## Packages

```{r}
pacman::p_load(tidyverse,
               here,
               janitor)
```

```{r}
#| echo: false
pacman::p_load(patchwork)
```

## Load data

-   two datasets today:
    -   `groesse_geburtstag_ws2324.csv`: a slightly changed `groesse_geburtstag` dataset from last week
    -   `languageR_english.csv`: condensed version of `english` dataset from the `languageR` package
-   if you don't have these data already, download them from Moodle

```{r}
#| eval: false
#| echo: false
library(languageR)

df_eng <- english |> 
  select(AgeSubject, Word, LengthInLetters, WrittenFrequency, WordCategory, RTlexdec, RTnaming) |>   mutate(RTlexdec = exp(RTlexdec),
         RTnaming = exp(RTnaming),
         RTnaming = ifelse(Word == "age" & AgeSubject == "young", NA, RTnaming)) 

write_csv(df_eng, here("daten", "languageR_english.csv"))

df_groesse <- read_csv(here("daten", "groesse_geburtstag_ws2324.csv"),
                       # fix N/A values
                       na = c("", "N/A")) |> 
  mutate(Gr√∂√üe = ifelse(Gr√∂√üe == 168, 167, Gr√∂√üe)) |> 
  clean_names() |> 
  rename(groesse = groesse,
         muttersprache = l1,
         geburtsmonat = monat_der_geburt,
         geburtstag = tag)

write_csv(df_groesse, here("daten", "groesse_geburtstag_ws2324.csv"))
```

```{r}
df_groesse <- read_csv(here("daten", "groesse_geburtstag_ws2324.csv"))
```

```{r}
df_eng <- read_csv(here("daten", "languageR_english.csv")) |> 
  clean_names() |> 
  # fix some wonky variable names:
  rename(rt_lexdec = r_tlexdec,
         rt_naming = r_tnaming)
```

# Deskriptive statistics

-   quantitatively describe the central tendency, variability, and distribution of data
    -   also called summary statistics
-   e.g., range of values (minimum, maximum), the mean value, and the standard deviation

## Number of observations ($n$)

-   not a statistic, but is important information
    -   more data (higher $n$) = more evidence
    -   less data (lower $n$) = may not be generalisable to the broader population
-   `nrow()`: get number of observations in a dataset

```{r}
#| output-location: fragment
nrow(df_groesse)
```

## Measures of central tendency

-   quantitavely describe the centre of our data
    -   the mean, median, and mode

### Mean ($\mu$)

-   the `mean`, or average: the sum of all values divided by the number of values (as in Equation \ref{eq-mean})

\begin{align}
\mu &= \frac{sum\;of\;values} 
           {n} \label{eq-mean} 
\end{align}

---

-   we can store the results of an equation as an object
    -   or multiple values as a vector (a list of values of the same class)

```{r}
#| output-location: fragment
# save heights as a vector
heights <- c(171, 168, 182, 190, 170, 163, 164, 167, 189)
```

-   we could then use the functions `sum()` and `length()` to compute the mean

```{r}
#| output-location: fragment
# divide the sum of heights by the n of heights
sum(heights)/length(heights)
```

-   or simply use the `mean()` function.

```{r}
#| output-location: fragment
# or use the mean() function
mean(heights)
```

---

-   we can also run the `mean()` function on a variable in a data frame by using the `$` operator (`dataframe$variable`).

```{r}
#| output-location: fragment
mean(df_groesse$groesse)
```

### Median

-   the value in the middle of the dataset
-   if you line up your data in order of value, half of the data lie below the median, and half above it

#### Median in R

-   we can use the `sort()` function and count which is the middle value:

```{r}
#| output-location: fragment
sort(df_groesse$groesse)
```

-   we could alternatively just use the function `median()`

```{r}
#| output-location: fragment
median(df_groesse$groesse)
```

### Mode

-   the value that occurs the most in a data set
-   no R function to determine the `mode`
    -   but we can visualise it, e.g., with a histogram or a density plot

```{r}
#| output-location: column-fragment
df_groesse |>
  ggplot(aes(x = groesse)) +
  geom_histogram(binwidth = .5) +
  theme_minimal() 
```

## Measures of dispersion

-   describe the spread of data points
    -   tell us something about how the data whole is distributed

### Range

-   can refer to the highest (maximum) and lowest (minimum) values
    -   or the difference between highest and lowest value

---

-   `max()` and `min()`: print the highest and lowest values

```{r}
#| output-location: fragment
max(heights)
```

```{r}
#| output-location: fragment
min(heights)
```

-   or use the `range()` function

```{r}
#| output-location: fragment
range(heights)
```

---

-   we can get the difference between these values by subtracting the minimum value from the maximum value

```{r}
#| output-location: fragment
max(heights) - min(heights)
```

---

-   In a histogram or density plot: the lowest and heights values on the x-axis

```{r}
#| echo: false
fig_hist <-
  df_groesse |> 
  ggplot() + 
  aes(x = groesse) + 
  labs(title = "Histogram of heights") +
  scale_y_continuous(breaks = c(1,2)) +
  geom_histogram(binwidth = .5)

fig_dens <-
  df_groesse |> 
  ggplot() + 
  aes(x = groesse) + 
  labs(title = "Density plot of heights") +
  geom_density()

fig_hist + fig_dens
```

### Standard deviation (`sd` or $\sigma$)

-   a measure of how dispersed data is *in relation to the mean*
    -   a low standard deviation means data are clustered around the mean (i.e., there is less spread)
    -   a high standard deviation means data are more spread out
-   standard deviation is very often reported whenever mean is reported

---

-   Standard deviation (`sd`) = the square root ($\sqrt{}$ or `sqrt()` in R) of the sum of squared value deviations from the mean ($(x - \mu)^2$) divided by the number of observations minus 1 ($n-1$)
    -   given in Equation \ref{eq-sd}

\begin{align}
\sigma & = \sqrt{\frac{(x_1-\mu)^2 + (x_2-\mu)^2 + ... + (x_N-\mu)^2}{N-1}} \label{eq-sd}
\end{align}

- this looks intimidating, but we can calcuate standard deviation in R using the `sd()` function

```{r}
#| output-location: fragment
sd(heights)
```

---

-   we can calculate standard deviation by hand if we know:
    -   the value of each observation
    -   the mean of these values
    -   the number of observations

\begin{align}
\sigma_{heights} & = \sqrt{\frac{(height_1-\mu)^2 + (height_2-\mu)^2 + ... (heights_N-\mu)^2}{N-1}} 
\end{align}

---

-   For example, in a vector with 3 observations (`3,5,9`), our values ($x$) are:

```{r}
#| output-location: column-fragment
values <- c(3,5,16)
values
```

- adding these to Equation \ref{eq-sd} we get Equation \ref{eq-sd1}

```{=tex}
\begin{align}
\sigma_{values} & = \sqrt{\frac{(3-\mu)^2 + (5-\mu)^2 + (16-\mu)^2}{N-1}} \label{eq-sd1}
\end{align}
```

---

- our mean ($\mu$) is:

```{r}
#| output-location: column-fragment
mean(values)
```

- adding these to Equation \ref{eq-sd1}, we get Equation \ref{eq-sd2}.

```{=tex}
\begin{align}
\sigma_{values} & = \sqrt{\frac{(3-8)^2 + (5-8)^2 + (16-8)^2}{N-1}} \label{eq-sd2}
\end{align}
```

---

- the number of observations ($n$) is:

```{r}
#| output-location: column-fragment
length(values)
```

- adding these to Equation \ref{eq-sd2} we get Equation \ref{eq-sd3}.

```{=tex}
\begin{align}
\sigma_{values} & = \sqrt{\frac{(3-8)^2 + (5-8)^2 + (16-8)^2}{3-1}} \label{eq-sd3}
\end{align}
```

---

- carrying out the remaining operations we get Equations \ref{eq-sd4} through \ref{eq-sd}:

```{=tex}
\begin{align}
\sigma_{values} & = \sqrt{\frac{(-5)^2 + (-3)^2 + (8)^2}{3-1}} \\ \label{eq-sd4}
\\
& = \sqrt{\frac{25 + 9 + 64}{3-1}}
\\
& = \sqrt{\frac{98}{2}} \\
& = \sqrt{49} \\
& = 7
\end{align}
```

- check our work:

```{r}
#| output-location: column-fragment
sd(values)
```

# Summary statistics with R

-   the `dplyr` package from the `tidyverse` has some helpful functions to produce summary statistics
-   let's now use the `df_eng` dataset to learn about these `dplyr` verbs.

## `dplyr::summarise`

-   `summarise()` function (`dplyr`) computes summaries of data
    -   but we have to tell it *what* to compute, and for which variable(s)
-   for example, the `n()` function produces the number of observations (only when used inside `summarise()` or `mutate()`)

```{r}
#| output-location: fragment
df_eng |>
  summarise(N = n())
```

---

-   we can also run multiple computations at once
    -   let's also generate the mean and standard deviation of the lexical decision task (`rt_lexdec`, in milliseconds)

```{r}
#| output-location: fragment
df_eng |>
  summarise(mean_lexdec = mean(rt_lexdec, na.rm=T),
            sd_lexdec = sd(rt_lexdec, na.rm = T),
            N = n()) 
```

---

::: callout-tip
## Missing values

- calculations aren't possible if there are missing values
  + the variable `rt_naming` has a missing value
  + the `mean()` function does not work with missing values

```{r}
#| output-location: column-fragment
df_eng |>
  summarise(mean_naming = mean(rt_naming))
```

- we can remove them using the verb `drop_na()`

```{r}
#| output-location: column-fragment
df_eng |>
  drop_na() |>
  summarise(mean_naming = mean(rt_naming))
```
:::

# Grouping variables

-   we usually want to *compare* certain groups
    -   e.g., comparing `groesse` between L1 speaker groups

## `.by =`

-   the `.by =` argument in `summarise()` computes our calculations on groups within a categorical variable

```{r}
#| output-location: fragment
#| code-line-numbers: "6"
df_eng |>
  drop_na() |>
  summarise(mean_lexdec = mean(rt_lexdec),
            sd_lexdec = sd(rt_lexdec),
            N = n(),
            .by = age_subject) |>
  arrange(mean_lexdec)
```

## Group by multiple variables

-   we can also group by multiple variables
    -   for this we need `concatenate` (`c()`)

---

```{r}
#| output-location: column-fragment
#| code-line-numbers: "6"
df_eng |>
  drop_na() |>
  summarise(mean_lexdec = mean(rt_lexdec),
            sd_lexdec = sd(rt_lexdec),
            N = n(),
            .by = c(age_subject, word_category)) |>
  arrange(age_subject)
```

# Anscombe's Quartet

-   Francis Anscombe constructed 4 datasets in 1973 to illustrate the importance of visualising data before analysing it and building a model
-   these four plots represent 4 datasets that all have nearly identical mean and standard deviation, but very different distributions

---


```{r}
#| echo: false
# https://michael-franke.github.io/intro-data-analysis/Chap-02-04-Anscombe-example.html
data("anscombe")
tidy_anscombe <- anscombe |>
  pivot_longer(
    everything(),
    names_pattern = "(.)(.)",      
    names_to = c(".value", "grp")  
  ) |>
  mutate(grp = paste0("Dataset ", grp)
         ) 
```

:::: columns
::: {.column width="50%"}
```{r}
#| label: tbl-anscombe
#| tbl-cap: Summary stats of Anscombe's quratet datasets
#| echo: false
tidy_anscombe |>
  group_by(grp) |>
  summarise(
    mean_x    = mean(x),
    mean_y    = mean(y),
    min_x     = min(x),
    min_y     = min(y),
    max_x     = max(x),
    max_y     = max(y),
    crrltn    = cor(x, y)
  ) |> 
  rename(dataset = grp) |> 
  mutate(mean_y = round(mean_y,1)) |>
  select(dataset, mean_x, mean_y) |> 
  knitr::kable() |>
  kableExtra::kable_styling(font_size=20)
```
:::
::: {.column width="50%"}

```{r}
#| label: fig-anscombe
#| fig-cap: Plots of Anscombe's quratet distributions
#| echo: false
#| fig-asp: 1
#| out-width: "100%"
tidy_anscombe |>
  ggplot(aes(x, y)) +
    geom_smooth(method = lm, se = F, color = "darkorange") +
    geom_point(size = 2) +
    scale_y_continuous(breaks = scales::pretty_breaks()) +
    scale_x_continuous(breaks = scales::pretty_breaks()) +
    labs(
      title = "Anscombe's Quartet", x = NULL, y = NULL,
      subtitle = bquote(y == 0.5 * x + 3 ~ (r %~~% .82) ~ "for all groups")
    ) +
    facet_wrap(~grp, ncol = 2, scales = "free_x") +
    theme(strip.background = element_rect(fill = "#f2f2f2", colour = "white")) +
  theme(axis.text = element_text(size = 30)) +
  theme_minimal()
```
:::
::::

## DatasaurRus

- datasauRus package [@datasauRus-package] contains some more datasets that have similar `mean` and `sd`, but different distributions
  + given in @tbl-datasauRus

```{r}
pacman::p_load("datasauRus")
```

```{r}
#| label: tbl-datasauRus
#| tbl-cap: Summary stats of datasauRus datasets
#| output-location: column-fragment
#| echo: false
datasaurus_dozen |>
    group_by(dataset) |>
    summarize(
      mean_x    = mean(x),
      mean_y    = mean(y),
      std_dev_x = sd(x),
      std_dev_y = sd(y),
      corr_x_y  = cor(x, y)
    ) |>
  mutate_if(is.numeric, round, 2) |> 
  knitr::kable() |>
  kableExtra::kable_styling(font_size = 20)
```

---

- but when we plot them, they all look very different (@fig-datasauRus)!

```{r}
#| label: fig-datasauRus
#| fig-cap: Plots of datasauRus dataset distributions
#| out-width: "100%"
#| fig-asp: .35
#| echo: false
ggplot(datasaurus_dozen, aes(x = x, y = y, colour = dataset))+
  geom_point(size = .8) +
  labs(title = "DatasauRus dataset distributions") +
  theme_minimal() +
  theme(legend.position = "none")+
  facet_wrap(~dataset, ncol = 7)
```

---

- so, ***always plot your data***
  + don't just look at the descriptive stats!!
- both are very important to understanding your data
- next week we'll see how to plot our summary statistics

# Learning objectives üèÅ {.unnumbered .unlisted}

Today we learned...

-   about measures of central tendency ‚úÖ
-   about measures of dispersion ‚úÖ
-   how to use the `summarise()` function from `dplyr` ‚úÖ
-   how to produce summaries `.by` group ‚úÖ

# Aufgaben

::: nonincremental
1.  Calculate the standard deviation of the values `152, 19, 1398, 67, 2111` without using the function `sd()`
    -   show your work. The following R syntax might be useful (depending on how you decide to do it):
        -   `c()`
        -   `mean()`
        -   `x^2` calculates the square of a value (here, `x`)
        -   `sqrt()` calculates the square root
        -   `length()` produces the number of observations in a vector

```{r}
#| echo: false
#| eval: false
x <- c(152, 19, 1398, 67, 2111)
sqrt((sum((x-mean(x))^2))/(length(x)-1))
```
:::

---

::: nonincremental
2.  Use the function `sd()` to print the standard deviation of the values above. Did you get it right?
3.  Using `summarise`, print the mean, standard deviation, and number of observations for `rt_naming` in the `df_lexdec` dataframe.
    -   Hint: do you need to remove missing values (`NA`s)?
4.  Do the same, but add the `.by()` argument to find the mean naming task response time (`rt_naming`) per month
    -   `arrange()` the output by the mean naming response time
:::

# Session Info {.unnumbered}

```{r}
#| eval: false
#| echo: false
RStudio.Version()$version
RStudio.Version()$release_name
```

Created with `r R.version.string` (`r R.version$nickname`) and RStudioversion 2023.9.0.463 (Desert Sunflower).

```{r}
sessionInfo()
```

# Literaturverzeichnis {.unlisted .unnumbered visibility="uncounted"}

::: {#refs custom-style="Bibliography"}
:::
